{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Time Series and Forecasting Intro \n",
    "\n",
    "**OBJECTIVES**\n",
    "\n",
    "- Know how to approach a time series forecasting problem.\n",
    "- Be able to make several baseline time series models.\n",
    "- Make exponential smoothing models including Holt-Winters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pdr.get_data_fred('HOUSTNSA', \"1980-01-01\", \"2023-11-28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = data.HOUSTNSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Methods\n",
    "\n",
    "- `rolling`\n",
    "- `diff`\n",
    "- `shift`\n",
    "- `pct_change`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth with mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pct_change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Common types of time series forecasting problems\n",
    "\n",
    "- Forecast a single value of the time series. (use y historic values of y to predict y at one point in the future)\n",
    "- Forecast a whole range of future values. (use historic values of y to predict y at many points in the future)\n",
    "- Use other features to aid in your forecast. (predict many y in the future and use y and X)\n",
    "- Forecast multiple time series simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before modeling\n",
    "- Get the time period into *datetime* dtype format\n",
    "- put it in the index\n",
    "- sort the index\n",
    "\n",
    "## Modeling considerations\n",
    "- Make sure you are clear what you are predicting (one value, a range of values, one-step-ahead that updates every time period?)\n",
    "- **Make sure you aren't leaking information from the future into your training data**\n",
    "- Make null baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Store sales data from Walmart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's forecast one single value one time period into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the dataset, set the index as a datetime index, sort it, and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:15.573361Z",
     "start_time": "2019-09-09T13:42:15.000892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-05</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store  Dept  Weekly_Sales  IsHoliday\n",
       "Date                                            \n",
       "2010-02-05      1     1      24924.50      False\n",
       "2010-02-12      1     1      46039.49       True\n",
       "2010-02-19      1     1      41595.55      False\n",
       "2010-02-26      1     1      19403.54      False\n",
       "2010-03-05      1     1      21827.90      False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/jfkoehler/nyu_bootcamp_fa23/main/data/train.csv', \n",
    "                   parse_dates=['Date'], index_col='Date')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-02-05', '2010-02-12', '2010-02-19', '2010-02-26',\n",
       "               '2010-03-05', '2010-03-12', '2010-03-19', '2010-03-26',\n",
       "               '2010-04-02', '2010-04-09',\n",
       "               ...\n",
       "               '2012-08-24', '2012-08-31', '2012-09-07', '2012-09-14',\n",
       "               '2012-09-21', '2012-09-28', '2012-10-05', '2012-10-12',\n",
       "               '2012-10-19', '2012-10-26'],\n",
       "              dtype='datetime64[ns]', name='Date', length=421570, freq=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:15.573361Z",
     "start_time": "2019-09-09T13:42:15.000892Z"
    }
   },
   "outputs": [],
   "source": [
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename sales column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Weekly_Sales': 'sales'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the DataFrame to Store 1 weekly sales only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:17.287774Z",
     "start_time": "2019-09-09T13:42:17.262841Z"
    }
   },
   "outputs": [],
   "source": [
    "store_1_data = data[data['Store'] == 1].copy()\n",
    "store_1_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_1_data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate all departments to compute the total sales per store. Keep only that column.\n",
    "\n",
    "Each department is in its own row, so you can aggregate sales by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:17.287774Z",
     "start_time": "2019-09-09T13:42:17.262841Z"
    }
   },
   "outputs": [],
   "source": [
    "store_1_sales = store_1_data.groupby(store_1_data.index)[['sales']].sum()\n",
    "store_1_sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:21.079629Z",
     "start_time": "2019-09-09T13:42:20.002510Z"
    }
   },
   "outputs": [],
   "source": [
    "store_1_sales.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the data to train and test. **The test set must come after the training set.** Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make the two datasets manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:23.025423Z",
     "start_time": "2019-09-09T13:42:23.017445Z"
    }
   },
   "outputs": [],
   "source": [
    "train = store_1_sales.loc[:'2012-1']\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = store_1_sales.loc['2012-2':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:25.897738Z",
     "start_time": "2019-09-09T13:42:24.856525Z"
    }
   },
   "outputs": [],
   "source": [
    "train['sales'].plot(label='train')\n",
    "test['sales'].plot(title='Weekly Sales for Store 1', label='test')\n",
    "plt.legend()\n",
    "plt.ylim(1.1E6, 2.5E6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Naive Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the last time period's sales and estimate the same value for all future time periods. This method is a **naive forecast**.\n",
    "\n",
    "$${\\Large \\hat y_{t+1} = y_t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a predictions DataFrame and set the predicted values equal to the last value in the `Sales` df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save our results in a *df_predictions* DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:28.230496Z",
     "start_time": "2019-09-09T13:42:27.565278Z"
    }
   },
   "outputs": [],
   "source": [
    "df_predictions = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take the last training dataset value and make that the guess for all future time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:28.230496Z",
     "start_time": "2019-09-09T13:42:27.565278Z"
    }
   },
   "outputs": [],
   "source": [
    "df_predictions['last'] = train['sales'].iloc[-1]\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the historic data, the actual \"future\" data, and the predicted \"future\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:42:28.230496Z",
     "start_time": "2019-09-09T13:42:27.565278Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 5))\n",
    "\n",
    "plt.plot(train['sales'], label='Train')\n",
    "plt.plot(test['sales'], label='Test')\n",
    "plt.plot(df_predictions['last'], label='Naive Last')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Naive Forecast');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score our model\n",
    "On RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_predictions['sales'], df_predictions['last'], squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's the most basic baseline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 2: Simple average of the training data\n",
    "Another baseline model. Maybe slightly better when the data don't have much of a trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['simple_mean'] = train['sales'].mean()\n",
    "df_predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(train['sales'], label='Train')\n",
    "plt.plot(test['sales'], label='Test')\n",
    "plt.plot(df_predictions['last'], label='Naive Last')\n",
    "plt.plot(df_predictions['simple_mean'], label='Historical Mean')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Naive Forecast');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_predictions['sales'], df_predictions['simple_mean'], squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Seasonality\n",
    "\n",
    "Forecast = 52 observations prior if you have weekly sales data and the seasonal pattern repeats every 52 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['seasonal'] = train['sales'].shift(52, freq='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(train['sales'], label='Train')\n",
    "plt.plot(test['sales'], label='Test')\n",
    "plt.plot(df_predictions['last'], label='Naive Last')\n",
    "plt.plot(df_predictions['simple_mean'], label='Historical Mean')\n",
    "plt.plot(df_predictions['seasonal'], label='Seasonal')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Baseline Forecasts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_predictions['sales'], df_predictions['seasonal'], squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 4: Simple Exponential Smoothing\n",
    "\n",
    "Smoothing just means using a moving average. Read more on moving averages from Hyndman [here](https://robjhyndman.com/papers/movingaverage.pdf).\n",
    "\n",
    "Simple exponential smoothing uses weighted averages where the weights decrease exponentially for older data points. \n",
    "\n",
    "$${\\Large\\hat y_{t+1} = \\alpha y_t + \\alpha (1-\\alpha)y_{t-1} + \\alpha(1-\\alpha)^2 y_{t-2} + ...}$$\n",
    "\n",
    "The one-step-ahead forecast for time `t+1` is a weighted average of all of the observations in the series (`y1,…,yt`). The rate at which the weights decrease is controlled by the parameter, `α` (which is between 0 and 1 with larger values of `α` meaning faster decay).\n",
    "\n",
    "**Older values matter less.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If alpha =.5: \n",
    "\n",
    "- What is the weight of the most recent observation (t)? \n",
    "- What is the weight of (t-1)?\n",
    "- What is the weight of (t-2)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use statsmodels for more advanced time series models to make life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing, ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = SimpleExpSmoothing(train['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ses.fit(smoothing_level=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best thing about statsmodels is the summary. \n",
    "\n",
    "Here you get lots of info: AIC, BIC, AICC, etc. 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) above are measures of how well the model fits. Lower is better. They consider the complexity of the model - like adjusted R2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast with `.forecast`\n",
    "\n",
    "Here you can just pass an integer for the number of forecasts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_forecast = model.forecast(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['ses'] = ses_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(train['sales'], label='Train')\n",
    "plt.plot(test['sales'], label='Test')\n",
    "plt.plot(df_predictions['last'], label='Naive Last')\n",
    "plt.plot(df_predictions['simple_mean'], label='Historical Mean')\n",
    "plt.plot(df_predictions['seasonal'], label='Seasonal')\n",
    "plt.plot(df_predictions['ses'], label='Simple Exponential Smoothing')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Baseline Forecasts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the smoothing level, but SES forecasts the same number every time, so this isn't going to be a winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 5: Holt-Winters' (additive and multiplicative versions)\n",
    "\n",
    "- Part of the exponential smoothing family of algorithms. \n",
    "- It's also called *Triple Exponential Smoothing*\n",
    "\n",
    "Holt-Winters' can handle trend and seasonality. It weights recent values more than old ones. This is a very strong classical time series model. 🎉\n",
    "\n",
    "#### Params to choose: \n",
    "- number of seasonal_periods\n",
    "- seasonal period effects additive or multiplicative\n",
    "- additive or multiplicative trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw = ExponentialSmoothing(\n",
    "    train['sales'],\n",
    "    seasonal_periods=52,\n",
    "    trend='add',\n",
    "    seasonal='mul'\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['hw'] = hw.forecast(len(test))\n",
    "df_predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(train['sales'], label='Train')\n",
    "plt.plot(test['sales'], label='Test')\n",
    "plt.plot(df_predictions['seasonal'], label='Seasonal')\n",
    "plt.plot(df_predictions['hw'], label=\"Holt-Winters'\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Baseline Forecasts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_predictions['sales'], df_predictions['hw'], squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why did Holt-Winters' work well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series dataset can be decomposed into its trend, seasonality, and residual components.\n",
    "\n",
    "Let's break down the components using statsmodels `seasonal_decompose` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decompose(store_1_sales, period=52).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holt-Winters' uses exponential smoothing and takes into account the trend and seasonality to forecast future sales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to choose the number of seasonal periods, and whether the trend and seasonal components are additive or multiplicative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two primary kinds of seasonality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive vs. Multiplicative Seasonality\n",
    "\n",
    "Seasonality can present itself in two ways:\n",
    "\n",
    "1. __Additive:__ the peaks and valleys keep the same magnitude over time.\n",
    "2. __Multiplicative:__ the peaks and valleys change in magnitude over time.\n",
    "\n",
    "You can plot the data over time to see which kind of seasonality effects the data show:\n",
    "\n",
    "#### Additive Seasonality\n",
    "<img src=\"assets/adding.png\" width=\"300px\">\n",
    "\n",
    "#### Multiplicative Seasonality\n",
    "<img src=\"assets/multi.png\" width=\"300px\">\n",
    "\n",
    "Alternatively, GridSearch it - or use a function that GridSearchs for you! 😀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see some ways to deal with the trend in the next lesson. For now, just know that Hyndman says don't use multiplicative for trend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Holt-Winters** method takes into account both trend and seasonality to forecast future sales. \n",
    "\n",
    "With this method, we will apply exponential smoothing to the seasonal components as well as the level and trend components. \n",
    "\n",
    "Here are the constituent parts of the additive model:\n",
    "\n",
    "<h3><center>Level Equation</center></h3> $$L_t = \\alpha (y_t - S_{t-s}) + (1 - \\alpha)(L_{t-1} + b_{t-1})$$ \n",
    "<h3><center>Trend Equation</center></h3> $$b_t = \\beta *(L_t - L_{t-1}) + (1 - \\beta)b_{t-1}$$\n",
    "<h3><center>Seasonality Equation</center></h3> $$S_t = \\gamma(y_t-L_t)+(1-\\gamma)S_{t-s}$$\n",
    "\n",
    "Combine these into a single equation: \n",
    "\n",
    "<h3><center>Forecast Equation</center></h3> $${\\Large F_{t+k} = L_t + kb_t+S_{t+k-s}}$$\n",
    "<br>\n",
    "\n",
    "(Where `α`, `β`, and `γ` are the smoothing parameters — each between 0 and 1 — and `s` is the length of the seasonal cycle.)\n",
    "\n",
    "* **The trend equation captures the overall direction of sales.** \n",
    "* The level equation is a weighted average between the seasonally adjusted observation and the non-seasonal forecast for time `t`. \n",
    "* The seasonal equation is a weighted average between the current seasonal index and the seasonal index of the same season `s` time periods ago. \n",
    "\n",
    "---\n",
    "#### Write out the train, test, and prediction DataFrames to pickle file format to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('./data/train.pkl')\n",
    "test.to_pickle('./data/test.pkl')\n",
    "df_predictions.to_pickle('./data/df_predictions.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If my observations are by the minute and there is a big spike in users once per week, what number should I use for seasonality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60*24*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter search to see if a different Holt Winter's model will perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for seasonal in ['add', 'mul']:\n",
    "    for trend in ['add', 'mul']:\n",
    "        hw = ExponentialSmoothing(\n",
    "            train['sales'],\n",
    "            seasonal_periods=52,\n",
    "            trend=trend,\n",
    "            seasonal=seasonal,\n",
    "        ).fit()\n",
    "        scores.append([trend, seasonal, hw.aic]) \n",
    "scores = pd.DataFrame(scores, columns=['trend', 'seasonal','AIC'])\n",
    "scores.sort_values('AIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a different store. Does the model perform similarly? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Pandas has exponential weighted functions, rolling functions, and expanding window transformations. Great for looking at historical data, but statsmodels is far better for making forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "## Check out the great free ebook: ⭐️\n",
    "[Forecasting: Principles and Practice by\n",
    "Rob J Hyndman & George Athanasopoulos](https://otexts.com/fpp3/) to learn more about time series. Hyndman is also behind a lot of the time series code and strategy in an R package that Python packages use.\n",
    "\n",
    "Jason Brownlee also has a lot of great information and Python code on time series forecasting at [Machine Learning Mastery](https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **Always sort your time series data by date**\n",
    "- **Make sure you aren't leaking information from the future into your training data**\n",
    "- Make baseline models first\n",
    "- Consider the tradeoffs between complexity and performance when choosing which model to use\n",
    "- Holt-Winters' Exponential Smoothing is really powerful and doesn't have too many parameters to choose\n",
    "- Seasonality is how many observations it takes for a pattern to repeat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
