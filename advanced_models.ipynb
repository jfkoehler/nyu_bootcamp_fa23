{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp-AVV8KY98i"
   },
   "source": [
    "### Ensemble models\n",
    "\n",
    "This lesson we aim to improve upon our decision tree models from last class and explore some alternative approaches to model building to overcome some of the drawbacks of the decision tree model. We will also discuss saving and resuse of models and explore a basic streamlit application.  \n",
    "\n",
    "- [Download and Install VSCode](https://code.visualstudio.com/)\n",
    "- [Install the Python extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python)\n",
    "\n",
    "**OBJECTIVES**\n",
    "\n",
    "- Identify shortcomings of Decision Tree models\n",
    "- Understand and Implement Ensemble models\n",
    "- Understand and Implement Boosted models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjJ55OfkbVKj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay \n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfes9SmC4SvN"
   },
   "source": [
    "### Decision Tree Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEBjKJv3bV8d"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "heart = pd.read_csv('https://raw.githubusercontent.com/jfkoehler/nyu_bootcamp_fa23/main/data/Heart.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QevzpjZnbYyC",
    "outputId": "fac07a07-ec9f-492f-f91b-1e85fac9ec30"
   },
   "outputs": [],
   "source": [
    "#inspect\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyNF4dzZ9pAx",
    "outputId": "eb594df5-1925-46c2-df7d-aba0a9d079ee"
   },
   "outputs": [],
   "source": [
    "#inspect\n",
    "heart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ct33W86IAGdq"
   },
   "outputs": [],
   "source": [
    "#drop missing values\n",
    "heart = heart.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "lLDX9JF8bgbl",
    "outputId": "f0a8c2e2-94c4-42a6-a449-fb85a13dd35f"
   },
   "outputs": [],
   "source": [
    "#target count\n",
    "sns.countplot(data = heart, x = 'AHD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQFRmMarbi46"
   },
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3WdGa_bbqmh"
   },
   "outputs": [],
   "source": [
    "#define X\n",
    "X = heart.drop('AHD', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline\n",
    "y = heart['AHD']\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bVpoKmi-EpT"
   },
   "outputs": [],
   "source": [
    "#define y (make it numeric)\n",
    "y = np.where(y == 'No', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T51knmCzbqjt"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97eQtzlc-iWW"
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "CmgEoLrZ-lPK",
    "outputId": "a06d683c-fb14-408f-aee3-15f4596d6e24"
   },
   "outputs": [],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V06FMOsB-lLn"
   },
   "outputs": [],
   "source": [
    "encoder = make_column_transformer((OneHotEncoder(), ['ChestPain', 'Thal']),\n",
    "                                  remainder = 'passthrough',\n",
    "                                  verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEAhGf8GbrDh"
   },
   "source": [
    "### Decision Tree\n",
    "\n",
    "To begin, we use a Decision Tree to model the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYqfvJxw-lJA"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocess', encoder),\n",
    "                 ('model', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP4ICmmjbtzm",
    "outputId": "9afc0004-5d37-48f6-d0c2-d5f426d57ca1"
   },
   "outputs": [],
   "source": [
    "#fit \n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "182STIwWbudf",
    "outputId": "65f61573-f8a1-4968-c935-f5429ba0ef21"
   },
   "outputs": [],
   "source": [
    "#accuracy\n",
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HurJXfN8bvQd",
    "outputId": "65ea83e1-6770-408a-9202-1213b1936549"
   },
   "outputs": [],
   "source": [
    "#confusion matrix for train and test\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**\n",
    "\n",
    "Use `.named_steps` to extract elements of pipeline -- here we want the `preprocess` step and to use the `get_feature_names_out` method to extract feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature names after transformations\n",
    "pipe.named_steps['preprocess'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "vSEFW8fGAS8n",
    "outputId": "64a1240e-bbe0-4e1d-cda9-4aace479fb92"
   },
   "outputs": [],
   "source": [
    "#visualize the tree\n",
    "plt.figure(figsize = (100, 100))\n",
    "plot_tree(pipe.named_steps['model'], \n",
    "          feature_names=pipe.named_steps['preprocess'].get_feature_names_out(),\n",
    "          fontsize = 50,\n",
    "          filled = True,\n",
    "          class_names = ['No', 'Yes']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUulMQM0b8eV"
   },
   "source": [
    "### Issues with Decision Trees\n",
    "\n",
    "When left alone, Decision Trees will overfit the data.  One approach to dealing with this would be to grid search different parameters and see if improved performance is possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMINDER**: When grid searching pipelines, name the step followed by two underscores followed by the parameter that you want to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2i1w4oVcAwM"
   },
   "outputs": [],
   "source": [
    "#decision tree parameters\n",
    "params = {'model__max_depth': [2, 3, 4, 5],\n",
    "          'model__min_samples_split': [2,3,4,5,6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9C5Ld_ZcADN",
    "outputId": "d2a43b41-4cbb-47ec-9c91-8468ffa89898"
   },
   "outputs": [],
   "source": [
    "#grid for searching\n",
    "grid = GridSearchCV(pipe, param_grid = params, cv = 2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyXU8YcYCC_o",
    "outputId": "bd670b90-7d11-4242-a4c4-21c0dd5d31d1"
   },
   "outputs": [],
   "source": [
    "#train score\n",
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dx4BfMHCEnj",
    "outputId": "bd90832d-8663-41fb-85c0-51fb61884941"
   },
   "outputs": [],
   "source": [
    "#test score\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SlnmJIdcBd5"
   },
   "source": [
    "### Ensemble methods\n",
    "\n",
    "One approach to improving our tree model is to consider it alongside other models we have already discussed and form a voting block for the models.  Here, each model is allowed a vote on the prediction.  Scikitlearn implements this idea with a `VotingClassifier` model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_AxpgvScq-U"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3eUUyb1ctww"
   },
   "outputs": [],
   "source": [
    "#voting approach\n",
    "voter = VotingClassifier([('tree1', DecisionTreeClassifier(max_depth = 2)),\n",
    "                          ('tree2',DecisionTreeClassifier(max_depth = 5)),\n",
    "                          ('tree3',DecisionTreeClassifier(min_samples_split=5))])\n",
    "vote_pipe = Pipeline([('preprocess', encoder),\n",
    "                      ('model', voter)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ayjj783ahGp1",
    "outputId": "bf5c6996-76a7-4947-ba2a-f0d099557b6e"
   },
   "outputs": [],
   "source": [
    "#fit it\n",
    "vote_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "su6LCrdFhGYQ",
    "outputId": "72b503eb-eb83-4d0e-a52a-d0280b6dbd4f"
   },
   "outputs": [],
   "source": [
    "vote_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5kjBwqFhGUj",
    "outputId": "8c7e89e0-b993-4f76-c051-e12310147e52"
   },
   "outputs": [],
   "source": [
    "vote_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVyF60O-Dp-k"
   },
   "source": [
    "### Bagging Classifier\n",
    "\n",
    "Building on the earlier ideas and taking them one step further, perhaps we build an ensemble of models on different samples of the data.  One such approach is referred to as **BAGGING**. Here, the samples are created with replacement -- **BOOTSTRAP** -- and the results are aggregated.  In classification this will be a vote either based on predictions or probabilities.\n",
    "\n",
    "- **BOOTSTRAP**:  \"*Bootstrapping is any test or metric that uses random sampling with replacement (e.g. mimicking the sampling process), and falls under the broader class of resampling methods*.\"\n",
    "\n",
    "- **BAGGING**: Aggregating bootstrapped models\n",
    "\n",
    "- **HARD VOTING**: Using majority of predicted values when ensembling\n",
    "\n",
    "- **SOFT VOTING**: Using probabilities to determine predictions from an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1LEaQr3FEI1"
   },
   "outputs": [],
   "source": [
    "#bagging pipeline\n",
    "bag_pipe = Pipeline([('preprocess', encoder),\n",
    "                     ('model', BaggingClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oSXxWwXFEGA",
    "outputId": "2fe8710d-f070-48d1-94c4-9ff833bfdd52"
   },
   "outputs": [],
   "source": [
    "#fit\n",
    "bag_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2drXLEcFED7",
    "outputId": "51912115-daf7-42a0-e29d-6b45a03ff781"
   },
   "outputs": [],
   "source": [
    "#train score\n",
    "bag_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Pk6bJgcFEBD",
    "outputId": "a981f081-7223-43d5-db93-05ec443ff35d"
   },
   "outputs": [],
   "source": [
    "#test score\n",
    "bag_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "YpRVoW5QFD4S",
    "outputId": "3c99dfd8-7c70-42e3-ecff-1eaa907ec932"
   },
   "outputs": [],
   "source": [
    "#confusion matrix on test\n",
    "ConfusionMatrixDisplay.from_estimator(bag_pipe, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XDzoux4ixAP"
   },
   "source": [
    "### Random Forests\n",
    "\n",
    "*Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the mean or average prediction of the individual trees is returned.*\n",
    "\n",
    "The main difference to bagging is that we are also sampling features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gwM95dSi0Ii"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X36XX37Bi0ET"
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "forest_pipe = Pipeline([('preprocess', encoder), \n",
    "                       ('model', RandomForestClassifier(max_depth = 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOugkZm3iz_5"
   },
   "outputs": [],
   "source": [
    "# fit\n",
    "forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozWSEr99iyte"
   },
   "outputs": [],
   "source": [
    "# train score\n",
    "forest_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test score\n",
    "forest_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DecisionTreeClassifier(max_depth = 3), DecisionTreeClassifier(max_depth = 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[['Age', 'Sex']]\n",
    "X2 = X[['RestBP', 'Chol']]\n",
    "models[0].fit(X1, y)\n",
    "models[1].fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].predict(X1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].predict(X2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe.named_steps['preprocess'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe.named_steps['model'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'features': forest_pipe.named_steps['preprocess'].get_feature_names_out(),\n",
    "             'importance': forest_pipe.named_steps['model'].feature_importances_ }).sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2x6JbPXMi00e"
   },
   "source": [
    "### Boosted Models\n",
    "\n",
    "An alternative to aggregating across models would be to iteratively update a model based on pervious performance.  This is what boosting does, and while we will gloss over most of the details -- the mechanism for updating the models is what determines the name of the boosted model.  \n",
    "\n",
    "Scikitlearn implements an `AdaBoostClassifier` and `GradientBoostedClassifier` both iteratively update models based on prior performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPL-gGDFlXza"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjqs3t8ElXuI"
   },
   "outputs": [],
   "source": [
    "#adaboost\n",
    "ada_pipeline = Pipeline([('preprocess', encoder), ('model', AdaBoostClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xL9a5KxvlXq9"
   },
   "outputs": [],
   "source": [
    "# fit and score\n",
    "ada_pipeline.fit(X_train, y_train)\n",
    "ada_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgS2KJNIlXn6"
   },
   "outputs": [],
   "source": [
    "#gradient boosting classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xa0vNZmDlWb5"
   },
   "outputs": [],
   "source": [
    "#fit and score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xgboost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate classifier\n",
    "xboost = xgb.XGBClassifier(n_estimators = 10, max_depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with out of the box settings\n",
    "boost_pipe = Pipeline([('encoder', encoder), \n",
    "                      ('model', xboost)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score it\n",
    "boost_pipe.fit(X_train, y_train)\n",
    "boost_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(boost_pipe.named_steps['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 20))\n",
    "xgb.plot_tree(boost_pipe.named_steps['model'], ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Persistence\n",
    "\n",
    "After building a model and identifying the optimal parameters its time to put it to use. The `pickle` module is one way to save and reuse python objects including sklearn models.  Below, we use the pickle module to save and load a list and sklearn model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out pickle file\n",
    "with open('alist.pkl', 'wb') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in pickle file\n",
    "with open('alist.pkl', 'rb') as f:\n",
    "    thelist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the list again\n",
    "thelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the boosted model as boost.pkl\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart[['Age', 'Sex', 'Slope']]\n",
    "y = heart['AHD']\n",
    "forest = RandomForestClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('streamlit_example/forestmodel.pkl', 'wb') as f:\n",
    "    pickle.dump(forest, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Simple Application\n",
    "\n",
    "Below is the code for a basic streamlit application.  This is a way to deploy and share your models.  For more options see the documentation [here](https://docs.streamlit.io/).\n",
    "\n",
    "```python\n",
    "import streamlit as st \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "st.header('A Model for AHD')\n",
    "\n",
    "st.write('Please enter the Age, Sex, and Slope information below.')\n",
    "\n",
    "age = st.number_input('Age')\n",
    "sex = st.number_input('Sex')\n",
    "slope = st.number_input('Slope')\n",
    "\n",
    "X = np.array([[age, sex, slope]])\n",
    "\n",
    "with open('forestmodel.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "pred = model.predict(X)\n",
    "\n",
    "st.write(f'The model predicts {pred[0]}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the app is created, you can run it by writing \n",
    "\n",
    "```\n",
    "streamlit run app.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
